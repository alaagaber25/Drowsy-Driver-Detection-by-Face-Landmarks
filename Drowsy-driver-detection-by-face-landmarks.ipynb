{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Drowsiness Detection Method Overview\n",
    "\n",
    "This project implements a drowsiness detection system that relies on monitoring the **Eye Aspect Ratio (EAR)**—a simple yet effective metric to determine whether a person’s eyes are open or closed.\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "- **Facial Landmark Detection:**\n",
    "  The system utilizes a pre-trained facial landmark predictor to locate key points on a person’s face. These points, especially those outlining the eyes, are critical for subsequent analysis.\n",
    "\n",
    "- **Calculating the Eye Aspect Ratio (EAR):**\n",
    "  The EAR is computed by comparing the vertical distances (between the eyelid landmarks) to the horizontal distance (between the corners of the eyes). Essentially, when the eyes are open, the vertical distances are relatively large compared to the horizontal distance. When the eyes begin to close, these vertical distances decrease, causing the EAR to drop.\n",
    "\n",
    "- **Determining Drowsiness:**\n",
    "  By monitoring the EAR over consecutive frames in a video stream, the system can detect when the eyes remain closed for an extended period. A consistently low EAR signals that the individual might be drowsy, at which point an alarm is activated to prompt alertness.\n",
    "\n",
    "This approach, based on real-time computer vision techniques, offers a reliable and efficient way to monitor and address drowsiness, especially in applications like driver alertness systems.\n",
    "\n",
    "![](https://learnopencv.com/wp-content/uploads/2022/09/03-driver-drowsiness-detection-EAR-points.png)\n"
   ],
   "id": "54451cc197ed4b06"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T13:28:37.106249Z",
     "start_time": "2025-02-28T13:28:37.102037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import necessary libraries\n",
    "from scipy.spatial import distance\n",
    "from imutils import face_utils\n",
    "import imutils\n",
    "import dlib\n",
    "import cv2\n",
    "import pygame\n",
    "import time"
   ],
   "id": "6428bcc7dd482d9b",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T13:28:37.124184Z",
     "start_time": "2025-02-28T13:28:37.119306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to calculate the Eye Aspect Ratio (EAR)\n",
    "def eye_aspect_ratio(eye):\n",
    "    A = distance.euclidean(eye[1], eye[5])\n",
    "    B = distance.euclidean(eye[2], eye[4])\n",
    "    C = distance.euclidean(eye[0], eye[3])\n",
    "    return (A + B) / (2.0 * C)\n"
   ],
   "id": "ca7d3b7fe04e3836",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T13:38:44.396794Z",
     "start_time": "2025-02-28T13:38:44.393182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Constants\n",
    "MODEL_PATH = \"shape_predictor_68_face_landmarks.dat\"\n",
    "ALARM_PATH = \"assets_alarm.mp3\"\n",
    "THRESH = 0.25\n",
    "FLAG_THRESH = 10"
   ],
   "id": "ee3226be5c444fcf",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T13:38:45.862510Z",
     "start_time": "2025-02-28T13:38:44.638957Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize face detector and shape predictor\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(MODEL_PATH)\n",
    "\n",
    "pygame.mixer.init()\n",
    "pygame.mixer.music.load(ALARM_PATH)"
   ],
   "id": "8d902441a62d52b5",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T13:38:45.871905Z",
     "start_time": "2025-02-28T13:38:45.867748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get eye landmark indexes\n",
    "print(imutils.face_utils.FACIAL_LANDMARKS_68_IDXS)\n",
    "(rStart, rEnd)=imutils.face_utils.FACIAL_LANDMARKS_68_IDXS['right_eye']\n",
    "(lStart, lEnd)=imutils.face_utils.FACIAL_LANDMARKS_68_IDXS['left_eye']"
   ],
   "id": "bd08e67fcc094ee4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('mouth', (48, 68)), ('inner_mouth', (60, 68)), ('right_eyebrow', (17, 22)), ('left_eyebrow', (22, 27)), ('right_eye', (36, 42)), ('left_eye', (42, 48)), ('nose', (27, 36)), ('jaw', (0, 17))])\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T15:05:39.192604Z",
     "start_time": "2025-02-28T15:05:26.522681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Start video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "flag = 0\n",
    "ALARM_ON = False\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray)\n",
    "\n",
    "    for face in faces:\n",
    "        landmarks = predictor(gray, face) #its type is object detection object, so to get the index for the eyes we need it to be in array format\n",
    "        landmarks = face_utils.shape_to_np(landmarks)\n",
    "\n",
    "        rightEye = landmarks[rStart:rEnd]\n",
    "        leftEye = landmarks[lStart:lEnd]\n",
    "\n",
    "        leftEAR = eye_aspect_ratio(leftEye)\n",
    "        rightEAR = eye_aspect_ratio(rightEye)\n",
    "        ear = (leftEAR + rightEAR) / 2.0\n",
    "\n",
    "        # Draw convex hull around each eye for visual feedback\n",
    "        leftEyeHull = cv2.convexHull(leftEye)\n",
    "        rightEyeHull = cv2.convexHull(rightEye)\n",
    "        cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)\n",
    "        cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)\n",
    "\n",
    "        if ear < THRESH:\n",
    "            flag += 1\n",
    "            print(flag)\n",
    "            if flag >= FLAG_THRESH :\n",
    "                time.sleep(.01)\n",
    "                cv2.putText(frame, \"****************Drowsy!****************\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                cv2.putText(frame, 'Sleeping Time: 00:' + str(flag) + ' sec', (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                pygame.mixer.music.play()\n",
    "        else:\n",
    "            flag = 0\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    if cv2.waitKey(30) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "9a9c8aa9c3b3280f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T15:03:39.068343Z",
     "start_time": "2025-02-28T15:03:39.064814Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "source": "",
   "id": "cf83402ae009bc4",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
